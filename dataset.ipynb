{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated and saved as dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "names = [\n",
    "    \"Alice Johnson\", \"Bob Smith\", \"Charlie Brown\", \"David Lee\", \"Emma Davis\", \"Fiona Clark\", \"George Harris\", \n",
    "    \"Hannah White\", \"Ian Martinez\", \"Julia Adams\", \"Kevin Lewis\", \"Liam Scott\", \"Mia Turner\", \"Nathan Hall\", \n",
    "    \"Olivia Allen\", \"Paul Wright\", \"Quincy Young\", \"Rachel King\", \"Samuel Walker\", \"Tina Nelson\",\n",
    "    \"Umar Khan\", \"Vera Brooks\", \"William Carter\", \"Xander Evans\", \"Yvonne Foster\", \"Zack Green\", \"Aaron Hughes\", \n",
    "    \"Bella Irving\", \"Cameron Johnson\", \"Diana Kim\", \"Ethan Long\", \"Faith Moore\", \"Gabriel Nelson\", \"Hailey Owens\", \n",
    "    \"Isaac Perez\", \"Jasmine Quinn\", \"Kyle Roberts\", \"Lara Simmons\", \"Mason Thompson\", \"Natalie Underwood\", \n",
    "    \"Oscar Vasquez\", \"Penelope Watson\", \"Quentin Xiong\", \"Rebecca Young\", \"Sebastian Zimmerman\", \"Taylor Anderson\", \n",
    "    \"Ulysses Bennett\", \"Valerie Cooper\", \"Walter Dixon\", \"Xenia Edwards\", \"Yosef Franklin\", \"Zara Grant\", \"Adam Hayes\", \n",
    "    \"Brooke Ingram\", \"Connor James\", \"Delilah King\", \"Evan Lewis\", \"Felicity Morgan\", \"Gavin Norris\", \"Holly Owens\", \n",
    "    \"Ian Parker\", \"Jessica Quinn\", \"Keith Russell\", \"Lillian Scott\", \"Matthew Turner\", \"Nicole Underwood\", \"Owen Vasquez\", \n",
    "    \"Paige Walker\", \"Quinn Xavier\", \"Ryan Young\", \"Sophia Zimmerman\", \"Thomas Anderson\", \"Uma Bennett\", \"Victoria Clark\", \n",
    "    \"Wesley Davis\", \"Xander Ellis\", \"Yara Franklin\", \"Zane Grant\", \"Amber Harris\", \"Brandon Ingram\", \"Catherine Johnson\", \n",
    "    \"Derek Kim\", \"Eleanor Long\", \"Felix Moore\", \"Grace Nelson\", \"Henry Owens\", \"Isla Perez\", \"Jack Quinn\", \"Kylie Roberts\", \n",
    "    \"Leo Simmons\", \"Madeline Thompson\", \"Nathan Underwood\", \"Olivia Vasquez\", \"Peter Watson\", \"Quincy Xiong\", \"Rose Young\", \n",
    "    \"Samuel Zimmerman\", \"Tessa Anderson\", \"Umar Bennett\", \"Violet Cooper\", \"Wyatt Dixon\", \"Xenia Edwards\", \"Yusuf Franklin\"\n",
    "]\n",
    "phone_numbers = [f\"+1-202-555-{random.randint(1000,9999)}\" for _ in range(100)]\n",
    "skills = [\"Python\", \"Machine Learning\", \"Data Analysis\", \"React\", \"Java\", \"SQL\", \"Cloud Computing\", \"Cybersecurity\", \"Natural Language Processing\", \"TensorFlow\"]\n",
    "companies = [\"Google\", \"Microsoft\", \"Amazon\", \"Facebook\", \"Tesla\", \"IBM\", \"Netflix\", \"Adobe\", \"Intel\", \"Twitter\"]\n",
    "\n",
    "# Generate dataset\n",
    "data = []\n",
    "for i in range(100):\n",
    "    resume_skills = random.sample(skills, k=random.randint(3, 6))\n",
    "    linkedin_skills = random.sample(skills, k=random.randint(3, 6))\n",
    "    internship = random.choice(companies)\n",
    "    duration = random.randint(1, 12)  # Internship duration in months\n",
    "    data.append([names[i], phone_numbers[i], resume_skills, linkedin_skills, internship, duration])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Name\", \"Phone Number\", \"Resume Skills\", \"LinkedIn Skills\", \"Internship\", \"Internship Duration\"])\n",
    "\n",
    "# Save dataset\n",
    "df.to_csv(\"dataset.csv\", index=False)\n",
    "print(\"Dataset generated and saved as dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Skills: ['tensorflow']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from rapidfuzz import process, fuzz\n",
    "import ast  # Safer than eval for parsing lists\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Extract all unique skills from dataset (ensure correct parsing)\n",
    "all_skills = set()\n",
    "for skills in df[\"Resume Skills\"].dropna().tolist() + df[\"LinkedIn Skills\"].dropna().tolist():\n",
    "    try:\n",
    "        parsed_skills = ast.literal_eval(skills)  # Safer parsing\n",
    "        all_skills.update([skill.lower() for skill in parsed_skills])  # Store lowercase for consistency\n",
    "    except:\n",
    "        continue  # Skip invalid rows\n",
    "\n",
    "# Function to extract skills from user input\n",
    "def extract_skills(user_input):\n",
    "    doc = nlp(user_input.lower())  # Convert input to lowercase for matching\n",
    "    extracted_skills = set()\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Consider only nouns and proper nouns\n",
    "            token_text = token.text.strip()\n",
    "\n",
    "            # Exact match first\n",
    "            if token_text in all_skills:\n",
    "                extracted_skills.add(token_text)\n",
    "                continue\n",
    "\n",
    "            # Use fuzzy matching as a fallback (threshold 85 for better accuracy)\n",
    "            match, score, _ = process.extractOne(token_text, all_skills, scorer=fuzz.ratio)\n",
    "            if score > 85:\n",
    "                extracted_skills.add(match)\n",
    "\n",
    "    return list(extracted_skills)\n",
    "\n",
    "# Example user input\n",
    "user_input = input(\"Describe your project and the skills needed: \")\n",
    "identified_skills = extract_skills(user_input)\n",
    "\n",
    "# Display extracted skills\n",
    "print(\"\\nIdentified Skills:\", identified_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Skills for Matching: ['TensorFlow']\n",
      "\n",
      "Top 10 People Who Can Help (sorted by experience):\n",
      "1. David Lee | Phone: +91-202-555-9309 | Internship Duration: 12 months\n",
      "2. Jessica Quinn | Phone: +91-202-555-3328 | Internship Duration: 12 months\n",
      "3. Ryan Young | Phone: +91-202-555-8384 | Internship Duration: 12 months\n",
      "4. Samuel Zimmerman | Phone: +91-202-555-4735 | Internship Duration: 12 months\n",
      "5. Nathan Hall | Phone: +91-202-555-3704 | Internship Duration: 11 months\n",
      "6. Olivia Allen | Phone: +91-202-555-4262 | Internship Duration: 11 months\n",
      "7. Tina Nelson | Phone: +91-202-555-7869 | Internship Duration: 11 months\n",
      "8. Xander Evans | Phone: +91-202-555-7205 | Internship Duration: 11 months\n",
      "9. Hailey Owens | Phone: +91-202-555-8588 | Internship Duration: 11 months\n",
      "10. Taylor Anderson | Phone: +91-202-555-4266 | Internship Duration: 11 months\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Ensure skills are properly parsed\n",
    "def parse_skills(skill_str):\n",
    "    try:\n",
    "        skills = ast.literal_eval(skill_str)  # Convert string to list safely\n",
    "        return [skill.lower() for skill in skills]  # Convert to lowercase for matching\n",
    "    except:\n",
    "        return []  # Return empty list if parsing fails\n",
    "\n",
    "df[\"Resume Skills\"] = df[\"Resume Skills\"].apply(parse_skills)\n",
    "df[\"LinkedIn Skills\"] = df[\"LinkedIn Skills\"].apply(parse_skills)\n",
    "\n",
    "# Function to find top 10 helpers with phone numbers\n",
    "def find_top_helpers(identified_skills):\n",
    "    identified_skills = [skill.lower() for skill in identified_skills]  # Normalize case\n",
    "    matching_candidates = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        resume_skills = set(row[\"Resume Skills\"])\n",
    "        linkedin_skills = set(row[\"LinkedIn Skills\"])\n",
    "\n",
    "        # Check if any extracted skill is in Resume or LinkedIn skills\n",
    "        if any(skill in resume_skills or skill in linkedin_skills for skill in identified_skills):\n",
    "            matching_candidates.append((row[\"Name\"], row[\"Phone Number\"], row[\"Internship Duration\"]))\n",
    "\n",
    "    # Sort by internship duration (descending order) and get top 10\n",
    "    top_helpers = sorted(matching_candidates, key=lambda x: x[2], reverse=True)[:10]\n",
    "\n",
    "    return top_helpers\n",
    "\n",
    "# Example usage\n",
    "identified_skills = ['TensorFlow']  # Use the extracted skills from NLP step\n",
    "print(\"\\nExtracted Skills for Matching:\", identified_skills)\n",
    "\n",
    "helpers = find_top_helpers(identified_skills)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nTop 10 People Who Can Help (sorted by experience):\")\n",
    "if not helpers:\n",
    "    print(\"No matching candidates found!\")\n",
    "else:\n",
    "    for i, (name, phone, duration) in enumerate(helpers, start=1):\n",
    "        print(f\"{i}. {name} | Phone: {phone} | Internship Duration: {duration} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\AAYUSH THE\n",
      "[nltk_data]     GREAT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
